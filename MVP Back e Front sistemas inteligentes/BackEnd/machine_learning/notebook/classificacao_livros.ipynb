{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVX5IfNOoSlv"
      },
      "source": [
        "## Projeto de Machine Learning para predicao do gênero literário de um livro a partir da sinopse\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "O projeto consiste em criar um modelo de machine learning que possa prever o gênero de um livro a partir da sinopse disponibilizada. Para isso sao comparados os algoritmos KNN, Árvore de Classificação, Naive Bayes e SVM para chegar ao melhor modelo, que entao pode ser utilizado para previsao de gêneros literários pelo utilizador."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQgxELKU08pA"
      },
      "source": [
        "## Configuração: Importação das bibliotecas necessárias."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Neste primeiro passo são importadas todas as bibliotecas necessárias para a configuracao, treinamento e selecao do melhor modelo.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4Jbu3aao08XG"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "import re\n",
        "import joblib"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3DO9kBKzqtH"
      },
      "source": [
        "## Carga de Dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Nesse passo os dados são exportados do dataset e são apresentadas algumas informações, como números de linhas e colunas a serem usados. Aqui é indicado o caminho para o dataset que vai ser usado para treinamento do modelo. Também sao especificados quais colunas e informacoes serao usadas no modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I7E3EYMi7aQs"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Configuração e Carregamento do Dataset ---\n",
            "Número total de linhas do Dataset: 2998\n",
            "\n",
            "Primeiras 5 linhas do dataset:\n",
            "   index                      title    genre  \\\n",
            "0      0          Drowned Wednesday  fantasy   \n",
            "1      1              The Lost Hero  fantasy   \n",
            "2      2  The Eyes of the Overworld  fantasy   \n",
            "3      3            Magic's Promise  fantasy   \n",
            "4      4             Taran Wanderer  fantasy   \n",
            "\n",
            "                                             summary  \n",
            "0   Drowned Wednesday is the first Trustee among ...  \n",
            "1   As the book opens, Jason awakens on a school ...  \n",
            "2   Cugel is easily persuaded by the merchant Fia...  \n",
            "3   The book opens with Herald-Mage Vanyel return...  \n",
            "4   Taran and Gurgi have returned to Caer Dallben...  \n"
          ]
        }
      ],
      "source": [
        "#  Configuração e Carregamento do Dataset \n",
        "\n",
        "print(\"Configuração e Carregamento do Dataset \")\n",
        "df = pd.read_csv('../dataset/data.csv')\n",
        "print(f\"Número total de linhas do Dataset: {len(df)}\")\n",
        "print(\"\\nPrimeiras 5 linhas do dataset:\")\n",
        "print(df.head())\n",
        "\n",
        "\n",
        "# Definindo as colunas e os gêneros a serem utilizados\n",
        "synopsis_column = 'summary'\n",
        "genre_column = 'genre'\n",
        "target_genres = ['horror', 'history', 'science', 'fantasy', 'thriller']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5eZSQe60NpX"
      },
      "source": [
        "## Filtragem dos dados e Separação entre treino e teste (holdout)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Nesse passo é feita a filtragem dos dados. Sao excluidas as linhas vazias, convesao do texto para minusculo, remocao de caracteres especiais e espacos e feita contagem e divisao do dataset em dados de treino e de teste. Para o modelo os dados de teste foram definidos em 20% e os dados de treino em 80%."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EhqdS3bP4M5I"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Pré-processamento e Filtragem dos Dados ---\n",
            "Dataset filtrado para os gêneros ['horror', 'history', 'science', 'fantasy', 'thriller'].\n",
            "Número de linhas após filtragem e remoção de vazios: 2499\n",
            "\n",
            "Contagem de exemplos por gênero no dataset filtrado:\n",
            "genre\n",
            "fantasy     500\n",
            "science     500\n",
            "history     500\n",
            "thriller    500\n",
            "horror      499\n",
            "Name: count, dtype: int64\n",
            "\n",
            "--- Divisão do Dataset ---\n",
            "Tamanho do conjunto de treino: 1999 amostras\n",
            "Tamanho do conjunto de teste: 500 amostras\n"
          ]
        }
      ],
      "source": [
        "#  Pré-processamento e Filtragem dos Dados \n",
        "print(\"\\n Pré-processamento e Filtragem dos Dados \")\n",
        "\n",
        "df_filtered = df[df[genre_column].isin(target_genres)].copy()\n",
        "df_filtered.dropna(subset=[synopsis_column, genre_column], inplace=True)\n",
        "df_filtered = df_filtered[df_filtered[synopsis_column].str.strip() != '']\n",
        "\n",
        "print(f\"Dataset filtrado para os gêneros {target_genres}.\")\n",
        "print(f\"Número de linhas após filtragem e remoção de vazios: {len(df_filtered)}\")\n",
        "print(\"\\nContagem de exemplos por gênero no dataset filtrado:\")\n",
        "print(df_filtered[genre_column].value_counts())\n",
        "\n",
        "# Função de limpeza de texto (converte texto para minúsculas, remove caracteres\n",
        "#que não são letras, números e remove espaços desnecessários)\n",
        "\n",
        "def clean_text(text):\n",
        "    text = str(text).lower()\n",
        "    text = re.sub(r'[^a-z0-9\\s]', '', text)\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text\n",
        "\n",
        "\n",
        "df_filtered[synopsis_column] = df_filtered[synopsis_column].apply(clean_text)\n",
        "\n",
        "# Divisão do Dataset \n",
        "\n",
        "print(\"\\n Divisão do Dataset \")\n",
        "\n",
        "X = df_filtered[synopsis_column]\n",
        "y = df_filtered[genre_column]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "print(f\"Tamanho do conjunto de treino: {len(X_train)} amostras\")\n",
        "print(f\"Tamanho do conjunto de teste: {len(X_test)} amostras\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QXlNM0pW0VVD"
      },
      "source": [
        "## Transformação de dados: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Modelos de Machine Learning em regra trabalham apenas com números e nao letras. Por isto nesse passo é feita a transformacao das letras em numeros atravez da vetorizacao TF-IDF, onde as numeros atribuidos a cada palavra representam a importancia deles no referido texto. A vetorizacao deve ser realizada tanto para o modelo de treino quanto para o de teste, e ao final o modelo é exportado para utilizacao nas entradas dos usuarios."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K8CALeUp0clo"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Texto transformado em representacao numerica.\n"
          ]
        }
      ],
      "source": [
        "# Representação de Texto (TF-IDF)\n",
        "\n",
        "#Funcao que transforma o texto em numeros. \n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=5000, stop_words='english')\n",
        "\n",
        "\n",
        "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
        "\n",
        "print(\"\\nTexto transformado em representacao numerica.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPFbOZzp0t9_"
      },
      "source": [
        "## Definicao dos algorítimos e parametros (utilização dos algoritmos KNN, Árvore de Classificação, Naive Bayes e SVM)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Neste passo definimos os modelos de classificacao a serem usados (KNN, Arvore de Classificacao, Naive Bayes e SVM). Tambem sao definidos os hiperparametros para otimizacao de cada modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "87MigG-l0w4T"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Modelos e seus respectivos parâmetros para otimização definidos.\n"
          ]
        }
      ],
      "source": [
        "#  Modelagem: Definição dos Algoritmos \n",
        "\n",
        "\n",
        "models_to_optimize = {\n",
        "    'Naive Bayes': MultinomialNB(),\n",
        "    'SVM': SVC(random_state=42),\n",
        "    'KNN': KNeighborsClassifier(),\n",
        "    'Decision Tree': DecisionTreeClassifier(random_state=42)\n",
        "}\n",
        "\n",
        "\n",
        "param_grids = {\n",
        "    'Naive Bayes': {\n",
        "        'alpha': [0.1, 0.5, 1.0, 2.0]\n",
        "    },\n",
        "    'SVM': {\n",
        "        'kernel': ['linear', 'rbf'],\n",
        "        'C': [0.1, 1, 10]\n",
        "    },\n",
        "    'KNN': {\n",
        "        'n_neighbors': [3, 5, 7, 9],\n",
        "        'weights': ['uniform', 'distance']\n",
        "    },\n",
        "    'Decision Tree': {\n",
        "        'max_depth': [None, 10, 20, 30],\n",
        "        'min_samples_split': [2, 5, 10]\n",
        "    }\n",
        "}\n",
        "\n",
        "print(\"Modelos e seus respectivos parâmetros para otimização definidos.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9wSb6J-0xgD"
      },
      "source": [
        "## Otimização de hiperparâmetros"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Neste passo é realizada a otimizacao dos hiperparametros definidos anteriormente. A ideia aqui é encontrar a melhor combinacao dos hiperparamentos para garantir o melhor funcionamento possivel do modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WZAdfQd5028d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Otimização de Hiperparâmetros com GridSearchCV ---\n",
            "\n",
            "Iniciando otimização para Naive Bayes...\n",
            "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
            "Otimização para Naive Bayes concluída.\n",
            "Melhores Parâmetros para Naive Bayes: {'alpha': 0.5}\n",
            "Melhor pontuação (CV Score) no treino para Naive Bayes: 0.7399\n",
            "\n",
            "Iniciando otimização para SVM...\n",
            "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
            "Otimização para SVM concluída.\n",
            "Melhores Parâmetros para SVM: {'C': 10, 'kernel': 'rbf'}\n",
            "Melhor pontuação (CV Score) no treino para SVM: 0.7193\n",
            "\n",
            "Iniciando otimização para KNN...\n",
            "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
            "Otimização para KNN concluída.\n",
            "Melhores Parâmetros para KNN: {'n_neighbors': 9, 'weights': 'distance'}\n",
            "Melhor pontuação (CV Score) no treino para KNN: 0.5488\n",
            "\n",
            "Iniciando otimização para Decision Tree...\n",
            "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
            "Otimização para Decision Tree concluída.\n",
            "Melhores Parâmetros para Decision Tree: {'max_depth': None, 'min_samples_split': 5}\n",
            "Melhor pontuação (CV Score) no treino para Decision Tree: 0.4522\n"
          ]
        }
      ],
      "source": [
        "#  Otimização de Hiperparâmetros com GridSearchCV \n",
        "print(\"\\n Otimização de Hiperparâmetros com GridSearchCV \")\n",
        "\n",
        "optimized_models = {} \n",
        "\n",
        "for name, model in models_to_optimize.items():\n",
        "    print(f\"\\nIniciando otimização para {name}...\")\n",
        "\n",
        "   \n",
        "    grid_search = GridSearchCV(model, param_grids[name], cv=5, scoring='accuracy', n_jobs=-1, verbose=1)\n",
        "    grid_search.fit(X_train_tfidf, y_train)\n",
        "\n",
        "    optimized_models[name] = grid_search.best_estimator_ # Armazena o modelo com os melhores hiperparâmetros\n",
        "\n",
        "    print(f\"Otimização para {name} concluída.\")\n",
        "    print(f\"Melhores Parâmetros para {name}: {grid_search.best_params_}\")\n",
        "    print(f\"Melhor pontuação (CV Score) no treino para {name}: {grid_search.best_score_:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D128qZcP03Kh"
      },
      "source": [
        "## Avaliação e comparação de resultados dos modelos treinados com os diferentes algoritmos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Agora é criada uma matriz que mostra visualmente os acertos e erros. As linhas representam os gêneros verdadeiros, e as colunas, os gêneros previstos. É ótimo para identificar quais gêneros seu modelo está confundindo.\n",
        "\n",
        "Seleção do Melhor Modelo: A lógica dentro do loop compara a acurácia de cada modelo no conjunto de teste. O modelo com a maior acurácia é identificado como best_model_name, e sua instância é armazenada em best_trained_model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lo7ImyhN06vj"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Avaliação e Comparação dos Modelos Otimizados ---\n",
            "\n",
            "--- Resultados para o Modelo Otimizado: Naive Bayes ---\n",
            "Acurácia no conjunto de teste: 0.7360\n",
            "Relatório de Classificação:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     fantasy       0.76      0.68      0.72       100\n",
            "     history       0.74      0.80      0.77       100\n",
            "      horror       0.71      0.72      0.71       100\n",
            "     science       0.71      0.77      0.74       100\n",
            "    thriller       0.77      0.71      0.74       100\n",
            "\n",
            "    accuracy                           0.74       500\n",
            "   macro avg       0.74      0.74      0.74       500\n",
            "weighted avg       0.74      0.74      0.74       500\n",
            "\n",
            "Matriz de Confusão:\n",
            " [[68  7 10 11  4]\n",
            " [ 3 80  5  7  5]\n",
            " [10  6 72  5  7]\n",
            " [ 5  6  7 77  5]\n",
            " [ 4  9  8  8 71]]\n",
            "\n",
            "--- Resultados para o Modelo Otimizado: SVM ---\n",
            "Acurácia no conjunto de teste: 0.7380\n",
            "Relatório de Classificação:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     fantasy       0.74      0.75      0.75       100\n",
            "     history       0.75      0.79      0.77       100\n",
            "      horror       0.73      0.70      0.71       100\n",
            "     science       0.74      0.77      0.75       100\n",
            "    thriller       0.72      0.68      0.70       100\n",
            "\n",
            "    accuracy                           0.74       500\n",
            "   macro avg       0.74      0.74      0.74       500\n",
            "weighted avg       0.74      0.74      0.74       500\n",
            "\n",
            "Matriz de Confusão:\n",
            " [[75  2  8 13  2]\n",
            " [ 4 79  3  4 10]\n",
            " [12  7 70  3  8]\n",
            " [ 6  5  6 77  6]\n",
            " [ 4 12  9  7 68]]\n",
            "\n",
            "--- Resultados para o Modelo Otimizado: KNN ---\n",
            "Acurácia no conjunto de teste: 0.5460\n",
            "Relatório de Classificação:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     fantasy       0.36      0.85      0.50       100\n",
            "     history       0.71      0.60      0.65       100\n",
            "      horror       0.75      0.45      0.56       100\n",
            "     science       0.68      0.41      0.51       100\n",
            "    thriller       0.72      0.42      0.53       100\n",
            "\n",
            "    accuracy                           0.55       500\n",
            "   macro avg       0.64      0.55      0.55       500\n",
            "weighted avg       0.64      0.55      0.55       500\n",
            "\n",
            "Matriz de Confusão:\n",
            " [[85  4  4  6  1]\n",
            " [30 60  2  3  5]\n",
            " [41  6 45  4  4]\n",
            " [44  7  2 41  6]\n",
            " [37  8  7  6 42]]\n",
            "\n",
            "--- Resultados para o Modelo Otimizado: Decision Tree ---\n",
            "Acurácia no conjunto de teste: 0.4500\n",
            "Relatório de Classificação:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     fantasy       0.40      0.42      0.41       100\n",
            "     history       0.45      0.43      0.44       100\n",
            "      horror       0.40      0.39      0.40       100\n",
            "     science       0.59      0.61      0.60       100\n",
            "    thriller       0.40      0.40      0.40       100\n",
            "\n",
            "    accuracy                           0.45       500\n",
            "   macro avg       0.45      0.45      0.45       500\n",
            "weighted avg       0.45      0.45      0.45       500\n",
            "\n",
            "Matriz de Confusão:\n",
            " [[42 18 18 13  9]\n",
            " [17 43 14  9 17]\n",
            " [21 11 39  7 22]\n",
            " [14  7  7 61 11]\n",
            " [10 17 19 14 40]]\n",
            "\n",
            "--- Comparação Final de Acurácia no Teste ---\n",
            "Naive Bayes: Acurácia = 0.7360\n",
            "SVM: Acurácia = 0.7380\n",
            "KNN: Acurácia = 0.5460\n",
            "Decision Tree: Acurácia = 0.4500\n",
            "\n",
            "O modelo com melhor desempenho geral no conjunto de teste é: **SVM** (Acurácia: 0.7380)\n"
          ]
        }
      ],
      "source": [
        "#  Avaliação e Comparação dos Modelos Otimizados \n",
        "print(\"\\n Avaliação e Comparação dos Modelos Otimizados \")\n",
        "\n",
        "\n",
        "results = {}\n",
        "best_model_name = None\n",
        "best_accuracy = 0\n",
        "best_trained_model = None\n",
        "\n",
        "for name, model in optimized_models.items():\n",
        "    y_pred = model.predict(X_test_tfidf)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    results[name] = {\n",
        "        'accuracy': accuracy,\n",
        "        'report': classification_report(y_test, y_pred, zero_division=0),\n",
        "        'confusion_matrix': confusion_matrix(y_test, y_pred)\n",
        "    }\n",
        "\n",
        "    print(f\"\\n--- Resultados para o Modelo Otimizado: {name} ---\")\n",
        "    print(f\"Acurácia no conjunto de teste: {accuracy:.4f}\")\n",
        "    print(\"Relatório de Classificação:\\n\", results[name]['report'])\n",
        "    print(\"Matriz de Confusão:\\n\", results[name]['confusion_matrix'])\n",
        "\n",
        "    if accuracy > best_accuracy:\n",
        "        best_accuracy = accuracy\n",
        "        best_model_name = name\n",
        "        best_trained_model = model \n",
        "\n",
        "print(\"\\n--- Comparação Final de Acurácia no Teste ---\")\n",
        "for name, res in results.items():\n",
        "    print(f\"{name}: Acurácia = {res['accuracy']:.4f}\")\n",
        "\n",
        "print(f\"\\nO modelo com melhor desempenho geral no conjunto de teste é: **{best_model_name}** (Acurácia: {best_accuracy:.4f})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7WxCjVT8CB2"
      },
      "source": [
        "## Exportação do modelo\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Aqui estamos exportando o modelo para que possamos utilizar na nossa API. Os modelos sera exportados no formato .joblib apos a execucao dos testes e definicao do melhor modelo/algoritimo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "1ZwRDv7_8D_W"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Exportação do Melhor Modelo ---\n",
            "Modelo 'SVM' exportado como 'best_genre_classifier_svm.joblib'\n",
            "Vetorizador TF-IDF exportado como 'tfidf_vectorizer.joblib'\n"
          ]
        }
      ],
      "source": [
        "# ---  Exportar o Melhor Modelo Escolhido ---\n",
        "print(\"\\n--- Exportação do Melhor Modelo ---\")\n",
        "\n",
        "if best_trained_model is not None:\n",
        "    model_filename = f'best_genre_classifier_{best_model_name.replace(\" \", \"_\").lower()}.joblib'\n",
        "    vectorizer_filename = 'tfidf_vectorizer.joblib'\n",
        "\n",
        "    joblib.dump(best_trained_model, model_filename)\n",
        "    joblib.dump(tfidf_vectorizer, vectorizer_filename)\n",
        "\n",
        "    print(f\"Modelo '{best_model_name}' exportado como '{model_filename}'\")\n",
        "    print(f\"Vetorizador TF-IDF exportado como '{vectorizer_filename}'\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhkcyYdl8Foe"
      },
      "source": [
        "## Exemplo de uso do modelo escolhido"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Aqui sao informados dados aleatorios para o modelo exportado para podermos testar se o mesmo esta funcionando corretamente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a8swOyxH8JCF"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Exemplo de Uso do Modelo Exportado ---\n",
            "\n",
            "Sinopse de teste: 'A young officer awaits a mythical invasion in a desolate fort, his life consumed by futile expectation.'\n",
            "Gênero previsto pelo modelo exportado: thriller\n"
          ]
        }
      ],
      "source": [
        "#  Exemplo de Como Usar o Modelo Exportado \n",
        "\n",
        "\n",
        "print(\"\\n Exemplo de Uso do Modelo Exportado \")\n",
        "if best_trained_model is not None:\n",
        "    loaded_model = joblib.load(model_filename)\n",
        "    loaded_vectorizer = joblib.load(vectorizer_filename)\n",
        "\n",
        "    test_synopsis = \"A young officer awaits a mythical invasion in a desolate fort, his life consumed by futile expectation.\"\n",
        "    cleaned_test_synopsis = clean_text(test_synopsis)\n",
        "    test_synopsis_tfidf = loaded_vectorizer.transform([cleaned_test_synopsis])\n",
        "    predicted_genre_loaded = loaded_model.predict(test_synopsis_tfidf)\n",
        "\n",
        "    print(f\"\\nSinopse de teste: '{test_synopsis}'\")\n",
        "    print(f\"Gênero previsto pelo modelo exportado: {predicted_genre_loaded[0]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusao"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Neste documento foram apresentados os passos para parametrizacao, teste e definicao de um modelo de machine learning, com boa aplicacao para o tipo de problema apresentado no projeto. Foram feitos testes para cada algoritimo e escolhido aquele que melhor se adequa. A partir da análise do resultado podemos concluir que apresenta resultado satisfatorio, sendo que nos testes realizados o resultado foi na maioria das vezes positivo.\n",
        "\n",
        "Apesar de neste projeto em específico não ter sido dado ênfase as praticas de seguranca da informacao e desenvolvimento de software seguro, estes são extremamente importantes num contexto em que o mundo atual é cada vez mais digital e as inforcamoes sensiveis das pessoas estao disponiveis em quantidades enormes de bancos de dados na internet, muitas vezes resguardados sem a seguranca necessaria.\n",
        "\n",
        "Este projeto em especifico nao utiliza dados sensiveis, apesar de nao sabermos a origem dos dados do dataset, extraido em site de acesso publico. Em analise inicial nao foram localizados dados que nao referentes a livro publicados e disponiveis a qualquer pessoa."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
